{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from process_data import TextPreprocess\n",
    "\n",
    "\n",
    "radonpy_data = pd.read_csv('./radonpy.csv')\n",
    "# Remove the space of column name\n",
    "radonpy_data.columns = radonpy_data.columns.str.replace(' ', '')\n",
    "\n",
    "smiles_list = radonpy_data['smiles'].tolist()\n",
    "\n",
    "smiles_process = TextPreprocess()\n",
    "word2index, index2word, word_count = smiles_process.create_vocabulary(smiles_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generative_model import VAE_Encoder, VAE_Decoder, VAE\n",
    "\n",
    "word_count = 39\n",
    "input_dim = 64\n",
    "latent_dim = 32\n",
    "nhead=1\n",
    "hidden_dim = 128\n",
    "output_dim = 39\n",
    "number_layer = 1\n",
    "\n",
    "encoder = VAE_Encoder(word_count=word_count, \n",
    "                      d_model=input_dim, \n",
    "                      latent_dim=latent_dim, \n",
    "                      nhead=nhead)\n",
    "\n",
    "decoder = VAE_Decoder(latent_dim=latent_dim,\n",
    "                      d_model=input_dim,\n",
    "                      hidden_dim=hidden_dim,\n",
    "                      output_dim=output_dim,\n",
    "                      num_layers=number_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 164])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = smiles_process.text_to_index(smiles_list, padding=True)\n",
    "x = torch.tensor(x, dtype=torch.int64)  # Convert to torch.long data type\n",
    "# Only use the first 10 samples\n",
    "x = x[:120]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z shape: torch.Size([120, 164, 32])\n",
      "mu shape: torch.Size([120, 164, 32])\n",
      "logvar shape: torch.Size([120, 164, 32])\n"
     ]
    }
   ],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "\n",
    "z, mu, logvar = vae.encoder(x)\n",
    "print('z shape:', z.shape)\n",
    "print('mu shape:', mu.shape)\n",
    "print('logvar shape:', logvar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE_Decoder(\n",
       "  (decoder): RNN(64, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=39, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Warning: The hidden shape is not the last time step, we extract the last time step\n",
      "Warning: The latent dimension is not the same as the hidden dimension, we do the linear transformation\n",
      "After linear transformation, the hidden shape is:  torch.Size([1, 120, 128])\n",
      "decoder_out shape: torch.Size([120, 164, 39])\n",
      "decoder_hidden shape: torch.Size([1, 120, 128])\n"
     ]
    }
   ],
   "source": [
    "decoder_x = torch.randn(120, 164, 64)\n",
    "hidden = torch.randn(120, 164, 32)\n",
    "\n",
    "decoder_out, decoder_hidden = vae.decoder(decoder_x, z)\n",
    "print('decoder_out shape:', decoder_out.shape)\n",
    "print('decoder_hidden shape:', decoder_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model \n",
    "from training import Data_loader, Training\n",
    "\n",
    "def loss_function(decoder_out, x):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    decoder_out = decoder_out.view(-1, 164)\n",
    "    # Convert x to float data type\n",
    "    x = x.float()\n",
    "    loss = criterion(decoder_out, x)\n",
    "    return loss\n",
    "    \n",
    "\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=0.001)\n",
    "\n",
    "# Traing the model\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    z, mu, logvar = vae.encoder(x)\n",
    "    decoder_out, decoder_hidden = vae.decoder(decoder_x, z)\n",
    "    print('decoder_out shape:', decoder_out.shape)\n",
    "    loss = loss_function(decoder_out, x)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch:', epoch, 'Loss:', loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([120, 164, 39]), torch.Size([120, 164]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out.shape, x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Warning: The hidden shape is not the last time step, we extract the last time step\n",
      "Warning: The latent dimension is not the same as the hidden dimension, we do the linear transformation\n",
      "After linear transformation, the hidden shape is:  torch.Size([1, 120, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([120, 164, 39]), torch.Size([1, 120, 128]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z, mu, logvar = vae.encoder(x)\n",
    "decoder_out, decoder_hidden = vae.decoder(decoder_x, z)\n",
    "decoder_out.shape, decoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, mu, logvar, decoder_out = vae(x, decoder_x)\n",
    "decoder_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8215, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class mlp(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(mlp, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "x = torch.randn(10, 5)\n",
    "y = torch.tensor([0, 1, 1, 1, 0, 0, 1, 0, 1, 1],dtype=torch.int64)\n",
    "model = mlp(5, 3, 6)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "pred = model(x)\n",
    "\n",
    "loss_value = loss(pred, y)\n",
    "loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([3, 8, 5])\n",
      "y shape: torch.Size([3, 8])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "seq_len = 8\n",
    "class_num = 5\n",
    "\n",
    "y = torch.tensor([[0, 1, 2, 3, 4, 0, 1, 2], [0, 1, 2, 3, 4, 0, 1, 2], [0, 1, 2, 3, 4, 0, 1, 2]], dtype=torch.int64)\n",
    "x = torch.randn(batch_size, seq_len, class_num)\n",
    "x = torch.softmax(x, dim=2)\n",
    "print('x shape:', x.shape)\n",
    "print('y shape:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0717, 0.5718, 0.2268, 0.0802, 0.0496],\n",
       "         [0.0244, 0.0448, 0.0856, 0.3895, 0.4556],\n",
       "         [0.2146, 0.0642, 0.3530, 0.2780, 0.0901],\n",
       "         [0.1565, 0.3633, 0.1562, 0.2299, 0.0942],\n",
       "         [0.0460, 0.3356, 0.1258, 0.3278, 0.1646],\n",
       "         [0.1453, 0.3395, 0.0956, 0.3170, 0.1027],\n",
       "         [0.1965, 0.0658, 0.0807, 0.1774, 0.4797],\n",
       "         [0.2449, 0.3520, 0.0967, 0.1083, 0.1980]],\n",
       "\n",
       "        [[0.1276, 0.6744, 0.0333, 0.0371, 0.1276],\n",
       "         [0.0917, 0.4395, 0.1376, 0.2452, 0.0860],\n",
       "         [0.1289, 0.0884, 0.4184, 0.0604, 0.3039],\n",
       "         [0.2570, 0.1424, 0.1081, 0.2276, 0.2649],\n",
       "         [0.2934, 0.2852, 0.2117, 0.0753, 0.1345],\n",
       "         [0.3455, 0.0548, 0.1700, 0.3496, 0.0800],\n",
       "         [0.1288, 0.7209, 0.0719, 0.0504, 0.0280],\n",
       "         [0.2694, 0.1529, 0.4755, 0.0610, 0.0412]],\n",
       "\n",
       "        [[0.6993, 0.0538, 0.0968, 0.0697, 0.0804],\n",
       "         [0.0193, 0.2882, 0.1796, 0.2169, 0.2960],\n",
       "         [0.2671, 0.0363, 0.0976, 0.1645, 0.4346],\n",
       "         [0.1713, 0.5003, 0.1073, 0.1362, 0.0849],\n",
       "         [0.2628, 0.2100, 0.0749, 0.3256, 0.1266],\n",
       "         [0.2062, 0.2241, 0.3701, 0.1093, 0.0903],\n",
       "         [0.7268, 0.0251, 0.0882, 0.1039, 0.0560],\n",
       "         [0.1035, 0.3511, 0.3581, 0.0576, 0.1297]]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
